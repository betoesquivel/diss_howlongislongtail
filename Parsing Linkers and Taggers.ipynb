{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from json_extractor import from_file_get_n_docs\n",
    "\n",
    "from tagged_document_parsing_lib import \\\n",
    "all_possible_mentions_for_surface_forms,\\\n",
    "generate_mentions_for_surface_form,\\\n",
    "flatten\n",
    "\n",
    "from stanford_parser import parse_stanford_doc\n",
    "from wikifier_parser import parse_wikifier_doc\n",
    "from tagme_parser    import parse_tagme_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_file_name = './50_tagged_by_stanford.jsonl'\n",
    "wikifier_file_name = './100_tagged_by_wikifier.jsonl'\n",
    "tagme_file_name = './100_tagged_by_tagme_with_raw_longtext_0_epsilon_dot1_includecategories_includeallspots.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_docs = from_file_get_n_docs(stanford_file_name, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikifier_docs = from_file_get_n_docs(wikifier_file_name, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagme_docs = from_file_get_n_docs(tagme_file_name, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Stanford\n",
    "From here on, parsing means, converting the output from the stanford tagger into one dictionary with two main keys: entities and tagged-words.\n",
    "\n",
    "Entities is a map with the entity surface_form and type in json form as a key, and a list of mentions in the doc as value.\n",
    "\n",
    "tagged-words is a map with a token word index as key, and the mention in which surface_form it is contained as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stanford_parsed_docs = [parse_stanford_doc(doc) for doc in stanford_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Wikifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wikifier_parsed_docs = [parse_wikifier_doc(doc) for doc in wikifier_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Tagme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tagged_document_parsing_lib import generate_mentions_for_surface_form\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_tagme_doc(doc):\n",
    "    indexed_tagme_annotations = defaultdict(lambda: [])\n",
    "    parsed_doc = {}\n",
    "    parsed_doc[u'tagged-words'] = {}\n",
    "    \n",
    "    raw_text = doc['raw']\n",
    "    parsed_doc[u'tokens'] = raw_text.split()\n",
    "\n",
    "    for i, annotation in enumerate(doc['annotations']):\n",
    "        all_possible_annotation_indexes = generate_mentions_for_surface_form(annotation['spot'])\n",
    "\n",
    "        surface_form = annotation['spot']\n",
    "        \n",
    "        start_word_index = raw_text[:annotation['start']].split().__len__()\n",
    "        end_word_index = start_word_index + len(surface_form.split())\n",
    "\n",
    "        annotation[u'start'] = start_word_index\n",
    "        annotation[u'end'] = end_word_index - 1\n",
    "\n",
    "        for index in all_possible_annotation_indexes:\n",
    "            indexed_tagme_annotations[json.dumps(index, ensure_ascii=False)].append(annotation)\n",
    "            \n",
    "        for i in range(start_word_index, end_word_index):\n",
    "            parsed_doc[u'tagged-words'][i] = copy.deepcopy(annotation)\n",
    "            \n",
    "    parsed_doc[u'entities'] = indexed_tagme_annotations\n",
    "    \n",
    "    return parsed_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagme_parsed_docs = map(parse_tagme_doc, tagme_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Andy Wilson'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
