{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name parse_stanford_document",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-867916a7f315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjson_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_file_get_n_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtagged_document_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_stanford_document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name parse_stanford_document"
     ]
    }
   ],
   "source": [
    "from json_extractor import from_file_get_n_docs\n",
    "from collections import defaultdict\n",
    "from tagged_document_parsers import parse_stanford_document\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_file_name = './50_tagged_by_stanford.jsonl'\n",
    "wikifier_file_name = './100_tagged_by_wikifier.jsonl'\n",
    "tagme_file_name = './100_tagged_by_tagme_longtext_0_epsilon_dot1_includecategories_includeallspots.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_docs = from_file_get_n_docs(stanford_file_name, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikifier_docs = from_file_get_n_docs(wikifier_file_name, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagme_docs = from_file_get_n_docs(tagme_file_name, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford to Mention Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starts_new_entity = lambda prev, curr: prev != curr and curr != 'O'\n",
    "is_in_entity = lambda prev, curr: prev == curr and curr != 'O'\n",
    "is_outside_entity = lambda prev, curr: prev != curr and curr == 'O'\n",
    "\n",
    "def parse_stanford_doc(doc):\n",
    "    previous_type = u'O'\n",
    "    start_word = 0\n",
    "    end_word = 0\n",
    "    surface_form = u''\n",
    "    type_counts = defaultdict(lambda: 0)\n",
    "    \n",
    "    document = {}\n",
    "    document['entities'] = defaultdict(lambda: {'counts': 0, 'mentions': []})\n",
    "    document[u'tagged-words'] = {}\n",
    "    for i, [w, t] in enumerate(doc):\n",
    "        if starts_new_entity(previous_type, t):\n",
    "            start_word = i\n",
    "            end_word = i\n",
    "            surface_form = w\n",
    "        elif is_in_entity(previous_type, t):\n",
    "            end_word = i\n",
    "            surface_form += u\" {0}\".format(w)\n",
    "        elif is_outside_entity(previous_type, t):\n",
    "            mention = {\n",
    "                u'surface-form': surface_form,\n",
    "                u'type': previous_type,\n",
    "            }\n",
    "            json_mention = json.dumps(mention, ensure_ascii=False)\n",
    "\n",
    "            type_counts[previous_type+u'_M'] += 1\n",
    "            type_counts[previous_type+u'_E'] += 1 if json_mention not in document['entities'] else 0\n",
    "            \n",
    "            document['entities'][json_mention]['counts'] += 1\n",
    "            document['entities'][json_mention]['mentions'].append({\n",
    "                'start' : start_word,\n",
    "                'end' : end_word\n",
    "            })\n",
    "            \n",
    "            mention['start'] = start_word\n",
    "            mention['end'] = end_word \n",
    "            for i in range(start_word, end_word + 1):\n",
    "                document[u'tagged-words'][i] = mention\n",
    "            \n",
    "            surface_form = u''\n",
    "            \n",
    "        previous_type = t\n",
    "    \n",
    "    document['ORG_MENTIONS'] = type_counts['ORGANIZATION_M']\n",
    "    document['LOC_MENTIONS'] = type_counts['LOCATION_M']\n",
    "    document['PER_MENTIONS'] = type_counts['PERSON_M']\n",
    "    document['ORG_ENTITIES'] = type_counts['ORGANIZATION_E']\n",
    "    document['LOC_ENTITIES'] = type_counts['LOCATION_E']\n",
    "    document['PER_ENTITIES'] = type_counts['PERSON_E']\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanford_parsed_docs = [parse_stanford_doc(doc) for doc in stanford_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford_parsed_docs[3]['tagged-words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
